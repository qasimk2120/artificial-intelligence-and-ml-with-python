{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f142737",
   "metadata": {},
   "source": [
    "# LangChain with OpenAI: Role-Based Prompting and Few-Shot Examples\n",
    "\n",
    "This notebook demonstrates the use of **LangChainâ€™s ChatOpenAI interface**\n",
    "to interact with OpenAI models using:\n",
    "\n",
    "- Basic single-prompt invocation  \n",
    "- Role-based prompting (System, Human, AI)  \n",
    "- Few-shot prompting using example AI responses  \n",
    "\n",
    "The focus is on **prompt structure and message sequencing**, not model training\n",
    "or fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbaa49",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Basic LangChain Usage\n",
    "\n",
    "This section demonstrates the most minimal interaction pattern:\n",
    "a single human prompt sent to the model, returning a generated response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ece495",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-5-nano\",  temperature=0.6, seed=50)  #model name  can be changed as per requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "response =  chat.invoke('''i've recently adopted a dog, Could you suggest some dog names?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ce83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9a2fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Role-Based Prompting\n",
    "\n",
    "LangChain supports structured messages with explicit roles:\n",
    "\n",
    "- **SystemMessage**: controls model behavior or persona  \n",
    "- **HumanMessage**: user input or request  \n",
    "- **AIMessage**: example assistant responses  \n",
    "\n",
    "These roles provide finer control over model behavior compared to\n",
    "a single prompt string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity = \"medium\"  # Options: \"low\", \"medium\", \"high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": verbosity},\"reasoning\":{\"effort\": \"medium\"}},\n",
    "    \n",
    "    )  #model name  can be changed as per requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s = SystemMessage(content=\"You are a Marv that reluctantly answers questions in a romantic tone.\")\n",
    "message_h = HumanMessage(content=\"I've recently adopted a dog, Can you suggest some dog names?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_s, message_h])  #invoke can take list of messages and also single message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d46c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc979a33",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting with AI Messages\n",
    "\n",
    "Few-shot prompting is demonstrated by including example **AIMessage**\n",
    "responses in the prompt sequence.\n",
    "\n",
    "Providing example assistant outputs helps the model infer\n",
    "the expected response style, but increases token usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  input(\"Enter your prompt: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3af6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h_dog = HumanMessage(content=\"I've recently adopted a dog, Can you suggest some dog names?\")\n",
    "message_ai_dog = AIMessage(content= '''Oh, absolutely. Because nothing screams \"I'm a reasonable pet owner like asking a chatbot to name your new furball.\n",
    "                       How about \"Bark Twain\"(if it's a literary hound)?''')\n",
    "\n",
    "message_h_cat = HumanMessage(content=\"I've recently adopted a cat, Can you suggest some cat names?\")\n",
    "\n",
    "message_ai_cat = AIMessage(content= '''Oh, absolutely. Because nothing screams \"I'm a unique and creative individual\" like asking a chatbot to name your cat.\n",
    "                       How about \"Furry McFurFace\", \"Sir Meowsalot\" , or \"Catastrophe\"?''')\n",
    "\n",
    "message_h_fish = HumanMessage(content=\"I've recently adopted a fish, Can you suggest some fish names?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": verbosity},\"reasoning\":{\"effort\": \"medium\"}},\n",
    "    \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h_dog, message_ai_dog, message_h_cat, message_ai_cat, message_h_fish])  #invoke can take list of messages and also single message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22adb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchains_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
