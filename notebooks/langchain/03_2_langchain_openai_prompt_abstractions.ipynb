{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40b294b",
   "metadata": {},
   "source": [
    "# LangChain Prompt Abstractions with OpenAI\n",
    "\n",
    "This notebook demonstrates how to use **LangChain prompt abstractions**\n",
    "to build reusable and parameterized chat prompts when working with\n",
    "OpenAI-powered chat models.\n",
    "\n",
    "The focus is on:\n",
    "- Creating reusable **system** and **human** prompt templates\n",
    "- Injecting dynamic values into prompts\n",
    "- Constructing chat prompts from multiple message roles\n",
    "- Executing prompts using `ChatOpenAI`\n",
    "\n",
    "This approach improves maintainability, consistency, and scalability\n",
    "when building LLM-powered applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c378e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a4f2f",
   "metadata": {},
   "source": [
    "## Creating Prompt Abstractions\n",
    "\n",
    "Prompt abstractions allow the reuse of structured prompt components\n",
    "across multiple interactions.\n",
    "\n",
    "In this example, we define:\n",
    "- A **system message template** to control assistant behavior\n",
    "- A **human message template** with dynamic placeholders\n",
    "- A **chat prompt template** that combines both messages\n",
    "\n",
    "This design separates *prompt structure* from *prompt values*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": 'low'},\"reasoning\":{\"effort\": \"medium\"}},\n",
    "    \n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1776f",
   "metadata": {},
   "source": [
    "## Defining System and Human Prompt Templates\n",
    "\n",
    "Prompt templates define reusable message structures with placeholders.\n",
    "\n",
    "- The **system template** controls the assistantâ€™s behavior\n",
    "- The **human template** represents user input with dynamic variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c485a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S = '{description}'\n",
    "TEMPLATE_H = '''I've recently adopted a {pet}. Could you suggest some {pet} names?'''\n",
    "\n",
    "message_template_s = SystemMessagePromptTemplate.from_template(template=TEMPLATE_S)\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template=TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d19ae",
   "metadata": {},
   "source": [
    "## Composing a Chat Prompt\n",
    "\n",
    "The individual message templates are combined into a single\n",
    "`ChatPromptTemplate`.\n",
    "\n",
    "This represents a complete, reusable chat prompt\n",
    "that can be invoked with different input values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce981ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb9996",
   "metadata": {},
   "source": [
    "## Injecting Prompt Values\n",
    "\n",
    "At runtime, placeholder values are injected into the chat prompt\n",
    "to produce a concrete prompt instance.\n",
    "\n",
    "This step converts a **template** into an **executable chat prompt**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value = chat_template.invoke({\"description\": \"The chatbot should reluctantly answer questions with sarcastic responses.\",\n",
    "\"pet\": \"dog\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2615e57",
   "metadata": {},
   "source": [
    "## Executing the Prompt with ChatOpenAI\n",
    "\n",
    "The finalized chat prompt is passed to the chat model,\n",
    "which generates a response based on the structured messages\n",
    "and injected values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response =  chat.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bdef8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- Creating reusable prompt abstractions in LangChain  \n",
    "- Separating prompt structure from runtime values  \n",
    "- Composing system and human messages into a chat prompt  \n",
    "- Executing structured prompts using `ChatOpenAI`  \n",
    "\n",
    "Prompt abstractions are essential for building scalable,\n",
    "maintainable LLM applications with consistent behavior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchains_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
