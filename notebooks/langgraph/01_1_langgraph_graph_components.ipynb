{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e42fe68",
   "metadata": {},
   "source": [
    "# Graph Components and Implementation with LangGraph\n",
    "\n",
    "This notebook demonstrates how to build **stateful execution graphs**\n",
    "using **LangGraph**.\n",
    "\n",
    "LangGraph allows complex workflows to be expressed as graphs where:\n",
    "- Nodes operate on a shared state\n",
    "- Edges control execution flow\n",
    "- Conditional routing enables dynamic behavior\n",
    "\n",
    "The focus here is on:\n",
    "- Defining state\n",
    "- Creating nodes\n",
    "- Connecting nodes with edges\n",
    "- Adding conditional execution paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c73d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import Runnable\n",
    "from collections.abc import Sequence\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c693179",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3253f",
   "metadata": {},
   "source": [
    "## Defining the Graph State\n",
    "\n",
    "LangGraph nodes communicate by reading from and writing to\n",
    "a shared **state** object.\n",
    "\n",
    "The state is defined using a `TypedDict` for clarity and type safety.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4abcbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Sequence[BaseMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba97a",
   "metadata": {},
   "source": [
    "## Initial State\n",
    "\n",
    "An initial state is created with a single user message.\n",
    "This state will be passed through the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864ddaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = State(messages = [HumanMessage(\"Could you give me a grook by Piet Hein ~ 90 words?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaaccddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"messages\"][0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f9ad6",
   "metadata": {},
   "source": [
    "## Chat Model Initialization\n",
    "\n",
    "A deterministic chat model is used as the core reasoning component\n",
    "within graph nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dffd162",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": 'low'}},\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b8001",
   "metadata": {},
   "source": [
    "## Defining Graph Nodes\n",
    "\n",
    "Each node is a function that:\n",
    "- Accepts the current state\n",
    "- Performs some computation\n",
    "- Returns an updated state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a927043",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(state[\"messages\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c324c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING chatbot:\")\n",
    "    \n",
    "    response = chat.invoke(state[\"messages\"])\n",
    "    response.pretty_print()\n",
    "    \n",
    "    return State(messages = [response])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feea38f",
   "metadata": {},
   "source": [
    "## Testing a Node Independently\n",
    "\n",
    "Nodes can be tested outside the graph\n",
    "to verify their behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1005285",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1796148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e338f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"chabot\", chatbot)\n",
    "graph.add_edge(START, \"chabot\")\n",
    "graph.add_edge(\"chabot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1900ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefa032",
   "metadata": {},
   "source": [
    "## Compiled Graph as a Runnable\n",
    "\n",
    "Compiled graphs implement the `Runnable` interface\n",
    "and can be invoked like other LangChain components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52f9210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(graph_compiled, Runnable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0def58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbbfe59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6292152",
   "metadata": {},
   "source": [
    "## Conditional Graph Execution\n",
    "\n",
    "LangGraph supports conditional routing,\n",
    "allowing the execution path to change dynamically\n",
    "based on the current state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f4de0",
   "metadata": {},
   "source": [
    "### Nodes with User Interaction\n",
    "\n",
    "The following nodes request user input\n",
    "to demonstrate dynamic graph behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf1c97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_question:\")\n",
    "    \n",
    "    print(\"What is your question?\")\n",
    "    \n",
    "    return State(messages = [HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1c69348",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question(State(messages = []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9475e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_another_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_another_question:\")\n",
    "    \n",
    "    print(\"Would you like to ask one more question (yes/no)?\")\n",
    "    \n",
    "    return State(messages = [HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f6f87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_another_question(State(messages = []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99e3cf",
   "metadata": {},
   "source": [
    "## Defining a Routing Function\n",
    "\n",
    "Routing functions determine the next node\n",
    "based on the current state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea98ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_function(state: State) -> Literal[\"ask_question\", \"__end__\"]:\n",
    "    \n",
    "    if state[\"messages\"][0].content == \"yes\":\n",
    "        return \"ask_question\"\n",
    "    else:\n",
    "        return \"__end__\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a839fb1",
   "metadata": {},
   "source": [
    "## Graph with Conditional Edges\n",
    "\n",
    "The graph is extended with multiple nodes\n",
    "and conditional execution paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8a886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f756c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"ask_question\", ask_question)\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "graph.add_node(\"ask_another_question\", ask_another_question)\n",
    "\n",
    "graph.add_edge(START, \"ask_question\")\n",
    "graph.add_edge(\"ask_question\", \"chatbot\")\n",
    "graph.add_edge(\"chatbot\", \"ask_another_question\")\n",
    "graph.add_conditional_edges(source = \"ask_another_question\", \n",
    "                            path = routing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "378c2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5be14117",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6b4e6",
   "metadata": {},
   "source": [
    "## Visualizing the Graph\n",
    "\n",
    "LangGraph provides an ASCII visualization\n",
    "to inspect execution flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b30a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_compiled.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f024146",
   "metadata": {},
   "source": [
    "## Executing the Graph\n",
    "\n",
    "The compiled graph is invoked with an initial state.\n",
    "Execution follows the defined edges and routing logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa1a67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled.invoke(State(messages = []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128b5c2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- Defining shared state with `TypedDict`\n",
    "- Creating graph nodes that operate on state\n",
    "- Building execution graphs with `StateGraph`\n",
    "- Adding conditional routing for dynamic execution\n",
    "- Visualizing and executing LangGraph workflows\n",
    "\n",
    "LangGraph enables expressive, stateful,\n",
    "and controllable LLM-driven workflows.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "langgraph_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
