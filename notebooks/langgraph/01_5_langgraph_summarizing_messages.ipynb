{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b09cc4",
   "metadata": {},
   "source": [
    "# LangGraph Summary-Based Memory Management\n",
    "\n",
    "This notebook demonstrates **summary-based memory** in LangGraph,\n",
    "a technique used to maintain conversational context while\n",
    "preventing unbounded message growth.\n",
    "\n",
    "Instead of keeping all past messages, the conversation is:\n",
    "- Summarized into a running abstract\n",
    "- Old messages are deleted\n",
    "- The summary is injected back into the prompt\n",
    "\n",
    "This pattern is commonly used in production conversational agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7cfb372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage, RemoveMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6123f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f690c",
   "metadata": {},
   "source": [
    "## Defining the Graph State\n",
    "\n",
    "The graph state extends `MessagesState` by adding a\n",
    "persistent `summary` field.\n",
    "\n",
    "- `messages` holds the most recent interaction\n",
    "- `summary` stores a compressed representation of prior context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a924e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed6613",
   "metadata": {},
   "source": [
    "### Verifying Optional Summary Field\n",
    "\n",
    "The summary field may not exist initially.\n",
    "A safe `.get()` check ensures graceful handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1518338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state = State()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e091d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(test_state.get(\"summary\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895845f",
   "metadata": {},
   "source": [
    "## Chat Model Initialization\n",
    "\n",
    "A lightweight deterministic model is used to\n",
    "focus on graph behavior rather than response quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "15fa3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\", \n",
    "    temperature=0, \n",
    "    model_kwargs= {\"text\":{\"verbosity\": 'low'}},\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d932c14",
   "metadata": {},
   "source": [
    "## Defining Graph Nodes\n",
    "\n",
    "Each node:\n",
    "- Reads from the shared state\n",
    "- Performs a task\n",
    "- Returns new state updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fe945636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_question:\")\n",
    "    \n",
    "    question = \"What is your question?\"\n",
    "    print(question)\n",
    "    \n",
    "    return State(messages = [AIMessage(question), HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "34c2b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING chatbot:\")\n",
    "    for i in state[\"messages\"]:\n",
    "        i.pretty_print()\n",
    "        \n",
    "    system_message = f'''\n",
    "    Here's a quick summary of what's been discussed so far:\n",
    "    {state.get(\"summary\", \"\")}\n",
    "    \n",
    "    Keep this in mind as you answer the next question.\n",
    "    '''\n",
    "    \n",
    "    response = chat.invoke([SystemMessage(system_message)] + state[\"messages\"])\n",
    "    response.pretty_print()\n",
    "    \n",
    "    return State(messages = [response])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421d95a",
   "metadata": {},
   "source": [
    "After each response, the user decides whether\n",
    "the conversation should continue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7754ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_another_question(state: State) -> State:\n",
    "    \n",
    "    print(f\"\\n-------> ENTERING ask_another_question:\")\n",
    "    \n",
    "    question = \"Would you like to ask one more question (yes/no)?\"\n",
    "    print(question)\n",
    "    \n",
    "    return State(messages = [AIMessage(question), HumanMessage(input())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae4069",
   "metadata": {},
   "source": [
    "## Summarizing and Deleting Old Messages\n",
    "\n",
    "This node:\n",
    "1. Converts recent messages into text\n",
    "2. Updates the running summary\n",
    "3. Deletes all existing messages\n",
    "4. Preserves context via the summary field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3704b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_and_delete_messages(state: State) -> State:\n",
    "    print(f\"\\n-------> ENTERING ENTERING summarize_and_delete_messages:\")\n",
    "    \n",
    "    new_conversation = \"\"\n",
    "    for i in state[\"messages\"]:\n",
    "        new_conversation += f\"{i.type}: {i.content}\\n\\n\"\n",
    "        \n",
    "    summary_instructions = f'''\n",
    "Update the ongoing summary by incorporating the new lines of conversation below.  \n",
    "Build upon the previous summary rather than repeating it so that the result  \n",
    "reflects the most recent context and developments.\n",
    "\n",
    "\n",
    "Previous Summary:\n",
    "{state.get(\"summary\", \"\")}\n",
    "\n",
    "New Conversation:\n",
    "{new_conversation}\n",
    "'''\n",
    "    \n",
    "    print(summary_instructions)\n",
    "    \n",
    "    summary = chat.invoke([HumanMessage(summary_instructions)])\n",
    "    \n",
    "    remove_messages = [RemoveMessage(id = i.id) for i in state[\"messages\"][:]]\n",
    "    \n",
    "    return State(messages = remove_messages, summary = summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd8bbe",
   "metadata": {},
   "source": [
    "## Conditional Routing\n",
    "\n",
    "If the user answers `\"yes\"`, the conversation is summarized\n",
    "and restarted. Otherwise, execution ends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "09594741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_function(state: State) -> Literal[\"summarize_and_delete_messages\", \"__end__\"]:\n",
    "    \n",
    "    if state[\"messages\"][-1].content == \"yes\":\n",
    "        return \"summarize_and_delete_messages\"\n",
    "    else:\n",
    "        return \"__end__\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97425554",
   "metadata": {},
   "source": [
    "## Building the Graph\n",
    "\n",
    "The graph combines:\n",
    "- Conversational flow\n",
    "- Summary-based memory\n",
    "- Controlled looping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5fdf451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2365fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"ask_question\", ask_question)\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "graph.add_node(\"ask_another_question\", ask_another_question)\n",
    "graph.add_node(\"summarize_and_delete_messages\", summarize_and_delete_messages)\n",
    "\n",
    "graph.add_edge(START, \"ask_question\")\n",
    "graph.add_edge(\"ask_question\", \"chatbot\")\n",
    "graph.add_edge(\"chatbot\", \"ask_another_question\")\n",
    "graph.add_conditional_edges(source = \"ask_another_question\", \n",
    "                            path = routing_function)\n",
    "graph.add_edge(\"summarize_and_delete_messages\", \"ask_question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2608d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "86a003bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a034db",
   "metadata": {},
   "source": [
    "## Executing the Graph\n",
    "\n",
    "The graph starts with an empty message history.\n",
    "Long-term context is preserved through summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d2a14a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_compiled.invoke(State(messages = []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23843a4e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- Extending `MessagesState` with a summary field\n",
    "- Summary-based memory for long conversations\n",
    "- Deleting old messages without losing context\n",
    "- Injecting summaries into system prompts\n",
    "- Building production-style conversational agents\n",
    "\n",
    "Summary-based memory is essential for\n",
    "scalable and cost-effective LLM systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph_env",
   "language": "python",
   "name": "langraph_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
