{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc86cb9",
   "metadata": {},
   "source": [
    "# ðŸ¤– BERT-Based Question Answering with Transformers\n",
    "\n",
    "This notebook demonstrates the application of a **pre-trained BERT model**\n",
    "for **extractive question answering** using the Transformers library.\n",
    "\n",
    "A BERT Large model fine-tuned on the **SQuAD dataset** is used to:\n",
    "- Encode a question and its supporting context  \n",
    "- Predict the start and end positions of an answer span  \n",
    "- Extract the answer directly from the source text  \n",
    "- Visualize model confidence across input tokens  \n",
    "\n",
    "This work highlights practical understanding of Transformer architectures,\n",
    "tokenization mechanics, and model interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83713f78",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Background\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a Transformer-based\n",
    "language model trained on large-scale text corpora, including:\n",
    "\n",
    "- BooksCorpus (~11,000 books)  \n",
    "- Wikipedia articles  \n",
    "\n",
    "### Key characteristics\n",
    "- Bidirectional contextual understanding  \n",
    "- Deep semantic representations  \n",
    "- Large-scale parameterization  \n",
    "  - **BERT Base**: ~110M parameters  \n",
    "  - **BERT Large**: ~340M parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5319ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model fine-tuned on SQuAD\n",
    "model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efcdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  BertForQuestionAnswering.from_pretrained(model_name)   #loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)   #loading the pre-trained tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b4618",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questionâ€“Context Encoding\n",
    "\n",
    "The model receives:\n",
    "- A natural language question  \n",
    "- A supporting context passage containing the answer  \n",
    "\n",
    "Both inputs are encoded together into a single sequence using\n",
    "model-specific tokenization and special boundary tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example question and text containing the answer\n",
    "question = \"When was the first dvd released?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4dbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_document = \"The first DVD (Digital Versatile Disc) was released on March 24, 1997. It was a movie titled 'Twister' and was released in Japan. DVDs quickly gained popularity as a replacement for VHS tapes and became a common format for storing and distributing digital video and data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = bert_tokenizer.encode_plus(text= question, text_pair=answer_document)  #tokenizing the question and answer text pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ec7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = encoding['input_ids']  #getting the input ids from the encoding\n",
    "sentence_embeddings = encoding['token_type_ids']   #getting the segment ids from the encoding\n",
    "tokens =  tokenizer.convert_ids_to_tokens(inputs)   #converting the input ids to tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bdd07",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Inference and Answer Extraction\n",
    "\n",
    "The question answering head predicts:\n",
    "- **Start logits** indicating where the answer begins  \n",
    "- **End logits** indicating where the answer ends  \n",
    "\n",
    "The most likely token span is selected as the final answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =  model(input_ids = torch.tensor([inputs]), token_type_ids= torch.tensor([sentence_embeddings]) )  #getting the model output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = torch.argmax(output.start_logits)\n",
    "end_index = torch.argmax(output.end_logits)\n",
    "\n",
    "print(start_index)\n",
    "print(end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ' '.join(tokens[start_index: end_index+1])  #getting the answer from the tokens\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f60286",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Token-Level Confidence Visualization\n",
    "\n",
    "Start and end logits are visualized to interpret how confidently\n",
    "the model selects the answer span across input tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b28ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scores = output.start_logits.detach().numpy().flatten()\n",
    "e_scores = output.end_logits.detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_labels = []   #we want token labels as a list of strings with token and its index\n",
    "for (i, token) in enumerate(tokens):\n",
    "    tokens_labels.append('{:} - {:>2}'.format(token, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d37b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  sns.barplot(x=tokens_labels, y=s_scores) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  sns.barplot(x=tokens_labels, y=e_scores)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afcfa5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrates the practical application of BERT for\n",
    "**extractive question answering**, including:\n",
    "\n",
    "- Transformer-based tokenization  \n",
    "- Questionâ€“context encoding  \n",
    "- Span-based answer prediction  \n",
    "- Token-level confidence visualization  \n",
    "\n",
    "The implementation reflects an applied understanding of modern\n",
    "NLP architectures and their real-world usage.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (huggingfaceenv)",
   "language": "python",
   "name": "huggingfaceenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
