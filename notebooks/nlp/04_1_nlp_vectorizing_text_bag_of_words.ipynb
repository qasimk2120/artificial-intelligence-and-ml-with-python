{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bad4413",
   "metadata": {},
   "source": [
    "## üìä Text Vectorization: Bag of Words and TF-IDF\n",
    "*(Personal Practice Notes)*\n",
    "\n",
    "Before applying machine learning to text, we must convert text into a **numerical format**.\n",
    "This process is known as **text vectorization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912b235",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Why Text Vectorization?\n",
    "\n",
    "Machine learning models cannot work directly with raw text.\n",
    "\n",
    "Text vectorization converts text into numbers so that:\n",
    "- documents can be compared mathematically\n",
    "- patterns can be learned by ML algorithms\n",
    "\n",
    "Two common text vectorization techniques are:\n",
    "1. **Bag of Words (BoW)**\n",
    "2. **TF-IDF (Term Frequency‚ÄìInverse Document Frequency)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac2a99",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Bag of Words (BoW)\n",
    "\n",
    "The **Bag of Words** model:\n",
    "- counts which words appear in which documents\n",
    "- ignores word order and grammar\n",
    "- represents text as word frequency vectors\n",
    "\n",
    "Each document becomes:\n",
    "- a row\n",
    "- each unique word becomes a column\n",
    "- values represent how often the word appears\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "#transforms a collection of text documents to a matrix of token counts\n",
    "#it breaks the text into words (tokens) and counts the occurrences of each word in the document\n",
    "#this gives us the numerical representation we need to apply machine learning techniques to text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c216e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [' Most shark attacks occur about 10 feet from the beach since that is where the people are',\n",
    "        'the efficiency with which he paired the socks in the drawer was quite admirable',\n",
    "        'carol drank the blood as if she were a vampire',\n",
    "        'giving directions that the mountains are to the west only works when you can see them',\n",
    "        'the sign said there was road work ahead so he decided to speed up',\n",
    "        'the gruff old man sat in the back of the bait shop grumbling to himself as he scooped out a handful of worms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d0de7",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Creating a Bag of Words Model\n",
    "\n",
    "We use **CountVectorizer** from scikit-learn to create a Bag of Words model.\n",
    "\n",
    "CountVectorizer:\n",
    "- tokenizes text into words\n",
    "- builds a vocabulary of unique words\n",
    "- counts how often each word appears in each document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a bag-of-words model is straight forward with CountVectorizer\n",
    "countvec = CountVectorizer()  #not passing any parameters uses default settings\n",
    "#sets up the vectorizer ready to learn the vocabulary of the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb3b05",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Interpreting the Bag of Words Output\n",
    "\n",
    "- Each **row** represents one document\n",
    "- Each **column** represents a word from the vocabulary\n",
    "- Each value shows how many times the word appears in that document\n",
    "\n",
    "This gives us a numerical representation suitable for machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ab7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countvec_fit = countvec.fit_transform(data)   #fit means the Countvectorizer looks through the text and learns which unique words appear in the data\n",
    "#this learns the vocabulary and transforms the text data into a matrix of token counts\n",
    "#transform converts the text into numbers by creating a matrix that counts how often each word occurs\n",
    "\n",
    "bag_of_words = pd.DataFrame(countvec_fit.toarray(), columns=countvec.get_feature_names_out())\n",
    "#.toarray() creates a regular two-dimensional array of numbers , which can be placed in dataframe\n",
    "#to label the columns we get the feature names (unique words) from the count vectorizer using get_feature_names_out()\n",
    "\n",
    "#get_feature_names_out() returns the actual words in the vocabulary learned from the text data\n",
    "print(bag_of_words)\n",
    "\n",
    "#each row relates to each piece of text in our data and each column reelated to one individual word from the vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0db98",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Binary Bag of Words Representation\n",
    "\n",
    "Sometimes we only care whether a word **appears or not**, not how many times.\n",
    "\n",
    "Setting `binary=True`:\n",
    "- assigns 1 if the word appears\n",
    "- assigns 0 if it does not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5117c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec_binary = CountVectorizer(binary=True)\n",
    "countvec_binary_fit = countvec_binary.fit_transform(data)\n",
    "bag_of_words_binary = pd.DataFrame(countvec_binary_fit.toarray(), columns=countvec_binary.get_feature_names_out())\n",
    "print(bag_of_words_binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd5909",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Limitations of the Bag of Words Model\n",
    "\n",
    "While Bag of Words is simple and effective, it has important limitations:\n",
    "\n",
    "- ‚ùå Ignores word order\n",
    "- ‚ùå Ignores context\n",
    "- ‚ùå Treats all words as equally important\n",
    "- ‚ùå Cannot capture meaning or relationships between words\n",
    "\n",
    "Because of these limitations, more advanced methods such as **TF-IDF** and\n",
    "**word embeddings** are often preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f255b6b",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ TF-IDF (Term Frequency‚ÄìInverse Document Frequency)\n",
    "\n",
    "TF-IDF improves upon Bag of Words by:\n",
    "- measuring how important a word is to a specific document\n",
    "- reducing the impact of very common words\n",
    "\n",
    "It considers:\n",
    "- how often a word appears in one document\n",
    "- how common that word is across all documents\n",
    "\n",
    "Words that are frequent in one document but rare overall receive higher scores.\n",
    "-Term frequency means how many times a word appears in a single document\n",
    "-inverse document frequency looks at how many times a word appears in the entire collection of documents\n",
    "-common words will have the lowest score while less common will have more score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010c1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5227c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [' Most shark attacks occur about 10 feet from the beach since that is where the people are',\n",
    "        'the efficiency with which he paired the socks in the drawer was quite admirable',\n",
    "        'carol drank the blood as if she were a vampire',\n",
    "        'giving directions that the mountains are to the west only works when you can see them',\n",
    "        'the sign said there was road work ahead so he decided to speed up',\n",
    "        'the gruff old man sat in the back of the bait shop grumbling to himself as he scooped out a handful of worms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec2c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01dbd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec_fit = tfidfvec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7ad1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10     about  admirable     ahead       are        as   attacks  \\\n",
      "0  0.257061  0.257061   0.000000  0.000000  0.210794  0.000000  0.257061   \n",
      "1  0.000000  0.000000   0.293641  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000   0.000000  0.000000  0.000000  0.292313  0.000000   \n",
      "3  0.000000  0.000000   0.000000  0.000000  0.222257  0.000000  0.000000   \n",
      "4  0.000000  0.000000   0.000000  0.290766  0.000000  0.000000  0.000000   \n",
      "5  0.000000  0.000000   0.000000  0.000000  0.000000  0.178615  0.000000   \n",
      "\n",
      "      back     bait     beach  ...      were     west     when     where  \\\n",
      "0  0.00000  0.00000  0.257061  ...  0.000000  0.00000  0.00000  0.257061   \n",
      "1  0.00000  0.00000  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "2  0.00000  0.00000  0.000000  ...  0.356474  0.00000  0.00000  0.000000   \n",
      "3  0.00000  0.00000  0.000000  ...  0.000000  0.27104  0.27104  0.000000   \n",
      "4  0.00000  0.00000  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "5  0.21782  0.21782  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "\n",
      "      which      with      work    works    worms      you  \n",
      "0  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  \n",
      "1  0.293641  0.293641  0.000000  0.00000  0.00000  0.00000  \n",
      "2  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  \n",
      "3  0.000000  0.000000  0.000000  0.27104  0.00000  0.27104  \n",
      "4  0.000000  0.000000  0.290766  0.00000  0.00000  0.00000  \n",
      "5  0.000000  0.000000  0.000000  0.00000  0.21782  0.00000  \n",
      "\n",
      "[6 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_bag = pd.DataFrame(tfidfvec_fit.toarray(), columns=tfidfvec.get_feature_names_out())\n",
    "print(tfidf_bag) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d2016",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Takeaways\n",
    "\n",
    "- Text vectorization is required to apply ML to text\n",
    "- Bag of Words represents text using word counts\n",
    "- Binary BoW captures presence instead of frequency\n",
    "- Bag of Words ignores order and context\n",
    "- TF-IDF helps highlight more informative words\n",
    "- Choosing the right representation depends on the task\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
